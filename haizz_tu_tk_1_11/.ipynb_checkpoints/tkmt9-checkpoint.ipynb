{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsccfSDERjBo"
   },
   "source": [
    "# ĐỀ KIỂM TRA CUỐI KỲ\n",
    "## Học phần: Tối ưu hoá cho Khoa học dữ liệu\n",
    "## Ngày: 08/12/2024\n",
    "## Lớp/Lớp học phần: DHKHDL18A. Thời gian: 75 phút"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Câu 1. (2 điểm)** Một công ty phải chuyển $800m^3$ cát tới địa điểm xây dựng ở bên kia sông bằng cách thuê một chiếc xà lan. Ngoài chi phí vận chuyển một lượt đi về là $100$ ngàn đồng của chiếc xà lan, công ty đó phải thiết kế một thùng hình hộp chữ nhật đặt trên xà lan để đựng cát (mỗi lượt đi về, xà lan chỉ chở 1 thùng). Chiếc thùng này không cần nắp, chi phí cho các mặt xung quanh là 1 triệu đồng/$m^2$, cho mặt đáy là 2 triệu đồng/$m^2$. Bài toán đặt ra là kích thước của chiếc thùng đó như thế nào để tổng chi phí vận chuyển là nhỏ nhất. \n",
    "\n",
    "(Lưu ý: Để cho đơn giản, giả sử rằng số chuyến xà lan không nhất thiết phải là số tự nhiên và cát chỉ được đổ ngang hoặc thấp hơn với phần trên của thành thùng, không có ngọn. Giả sử thêm rằng xà lan rộng vô hạn và chứa được sức nặng vô hạn.)\n",
    "\n",
    "**a) (1 điểm)** Giả sử $x=(x_1,x_2,x_3)$ với $x_1,x_2,x_3$ lần lượt là chiều dài, chiều rộng và chiều cao của chiếc thùng. Hãy mô hình hoá bài toán trên dưới dạng bài toán tối ưu sau (chỉ ra công thức cho hàm $f(x)$)\n",
    "$$\\min_{x=(x_1,x_2,x_3)\\in\\mathbb{R}^3}\\;\\;\\; f(x)$$\n",
    "$$\\text{subject to }\\;\\;\\;  x_1>0,x_2>0,x_3>0.$$\n",
    "\n",
    "**b) (0.5 điểm)** Chứng minh rằng $f$ là hàm lồi.\n",
    "\n",
    "**c) (0.5 điểm)** Giải bài toán trên.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# =====================================================\n",
    "# (a) MÔ HÌNH HÓA HÀM MỤC TIÊU\n",
    "# =====================================================\n",
    "\n",
    "# biến\n",
    "x1, x2, x3 = sp.symbols('x1 x2 x3', positive=True, real=True)\n",
    "\n",
    "# hàm mục tiêu (triệu đồng)\n",
    "f_sym = (\n",
    "    2*x1*x2\n",
    "    + 2*x1*x3\n",
    "    + 2*x2*x3\n",
    "    + 80/(x1*x2*x3)\n",
    ")\n",
    "\n",
    "print(\"===== (a) HÀM MỤC TIÊU =====\")\n",
    "sp.pprint(f_sym)\n",
    "\n",
    "# =====================================================\n",
    "# (b) CHỨNG MINH HÀM LỒI (QUA HESSIAN)\n",
    "# =====================================================\n",
    "\n",
    "# gradient và Hessian\n",
    "grad_f = sp.Matrix([sp.diff(f_sym, v) for v in (x1, x2, x3)])\n",
    "H_f = grad_f.jacobian([x1, x2, x3])\n",
    "\n",
    "print(\"\\n===== (b) HESSIAN CỦA f =====\")\n",
    "sp.pprint(H_f)\n",
    "\n",
    "# kiểm tra xác định dương tại 1 điểm dương bất kỳ\n",
    "H_num = sp.lambdify((x1, x2, x3), H_f, 'numpy')\n",
    "\n",
    "test_point = (1.0, 1.0, 1.0)\n",
    "eigvals = np.linalg.eigvals(H_num(*test_point))\n",
    "\n",
    "print(\"\\nEigenvalues của Hessian tại (1,1,1):\")\n",
    "print(eigvals)\n",
    "\n",
    "if np.all(eigvals > 0):\n",
    "    print(\"⇒ Hessian xác định dương → f là hàm lồi\")\n",
    "else:\n",
    "    print(\"⇒ Hessian không xác định dương\")\n",
    "\n",
    "# =====================================================\n",
    "# (c) GIẢI BÀI TOÁN TỐI ƯU\n",
    "# =====================================================\n",
    "\n",
    "# hàm số cho scipy\n",
    "def f_numeric(x):\n",
    "    x1, x2, x3 = x\n",
    "    return (\n",
    "        2*x1*x2\n",
    "        + 2*x1*x3\n",
    "        + 2*x2*x3\n",
    "        + 80/(x1*x2*x3)\n",
    "    )\n",
    "\n",
    "# ràng buộc x > 0\n",
    "bounds = [(1e-6, None), (1e-6, None), (1e-6, None)]\n",
    "\n",
    "# điểm khởi tạo\n",
    "x0 = np.array([2.0, 2.0, 2.0])\n",
    "\n",
    "res = minimize(f_numeric, x0, bounds=bounds)\n",
    "\n",
    "print(\"\\n===== (c) NGHIỆM TỐI ƯU =====\")\n",
    "print(\"x* =\", res.x)\n",
    "print(\"Chi phí tối thiểu (triệu đồng) =\", res.fun)\n",
    "\n",
    "# kiểm tra đối xứng\n",
    "print(\"\\nKiểm tra x1 ≈ x2 ≈ x3:\", res.x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài toán tối ưu hóa thùng chứa cát\n",
    "\n",
    "\n",
    "### a) Mô hình hóa bài toán\n",
    "Giả sử $(x_1, x_2, x_3 > 0)$ lần lượt là chiều dài, chiều rộng và chiều cao của thùng chứa. \n",
    "\n",
    "- Thể tích thùng: $(x_1x_2x_3 = 800)$.\n",
    "- Diện tích mặt đáy: $(x_1x_2)$, chi phí là $(2 \\cdot x_1x_2)$ triệu đồng.\n",
    "- Diện tích các mặt xung quanh: $(2x_1x_3 + 2x_2x_3)$, chi phí là $(1 \\cdot (2x_1x_3 + 2x_2x_3))$ triệu đồng.\n",
    "- Tổng chi phí vận chuyển mỗi lượt: $(0.1)$ triệu đồng.\n",
    "\n",
    "Hàm chi phí tổng cần tối thiểu hóa là:\n",
    "\n",
    "$$\n",
    "f(x_1, x_2, x_3) = 0.1 + 2x_1x_2 + 2x_1x_3 + 2x_2x_3\n",
    "$$\n",
    "\n",
    "Ràng buộc:\n",
    "$$\n",
    "g(x_1, x_2, x_3) = x_1x_2x_3 - 800 = 0\n",
    "$$\n",
    "\n",
    "Bài toán tối ưu được viết lại:\n",
    "\n",
    "$$\n",
    "\\min_{x_1, x_2, x_3 > 0} f(x_1, x_2, x_3)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### b) Chứng minh hàm $( f(x) )$ là hàm lồi\n",
    "\n",
    "Hàm $(f(x_1, x_2, x_3) = 2x_1x_2 + 2x_1x_3 + 2x_2x_3)$ là tổng các tích $(x_i x_j$) ($(i \\neq j)$).\n",
    "\n",
    "- Các số hạng $(x_1x_2, x_1x_3, x_2x_3)$ đều là hàm lồi, vì Hessian của từng số hạng là bán xác định dương.\n",
    "- Tổng của các hàm lồi cũng là một hàm lồi.\n",
    "\n",
    "Do đó, \\(f(x)\\) là hàm lồi.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def cost_function(x):\n",
    "    x1, x2, x3 = x\n",
    "    return 2 * x1 * x2 + 2 * x1 * x3 + 2 * x2 * x3\n",
    "\n",
    "def volume_constraint(x):\n",
    "    return x[0] * x[1] * x[2] - 800\n",
    "\n",
    "bounds = [(1e-3, None), (1e-3, None), (1e-3, None)]\n",
    "\n",
    "initial_guess = [10, 10, 10]\n",
    "\n",
    "constraints = {'type': 'eq', 'fun': volume_constraint}\n",
    "\n",
    "result = minimize(cost_function, initial_guess, constraints=constraints, bounds=bounds)\n",
    "\n",
    "x_optimal = result.x\n",
    "f_min = result.fun\n",
    "\n",
    "print(f\"Kích thước tối ưu của thùng: x1 = {x_optimal[0]:.4f}, x2 = {x_optimal[1]:.4f}, x3 = {x_optimal[2]:.4f}\")\n",
    "print(f\"Chi phí tối thiểu: {f_min:.4f} triệu đồng\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Câu 2. (3 điểm)** Cho ma trận $P=\\begin{bmatrix}1 & 0\\\\ 0 & 4 \\end{bmatrix}$ và vector $q=(-1;4)$. Xét bài toán tối ưu sau \n",
    "$$\\min_{x\\in\\mathbb{R}^2}f(x)=\\dfrac{1}{2}x^TPx+q^Tx+\\dfrac{5}{2}\\quad \\quad (1).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) (1 điểm)** Xác định điểm tối ưu $x^*$ và giá trị tối ưu $p^*$ của bài toán (1).\n",
    "\n",
    "**b) (2 điểm)** Sử dụng thuật toán Gradient Descent cho bài toán $(1)$, với giá trị $x$ ban đầu là $x^{(0)}=(-1;2)$, sử dụng learning rate lần lượt là $0.4$ và $0.6$ và thực hiện tối đa $100$ vòng lặp. In ra giá trị của $x^{(k)}$, $f(x^{(k)})$ tương ứng sau mỗi vòng lặp $k$ và vẽ đồ thị biểu thị cho sai số $|f(x^{(k)})-p^*|$ trong cả hai trường hợp của learning rate. Từ đó hãy đưa ra kết luận về sự hội tụ của thuật toán Gradient Descent trong từng trường hợp của learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) (1 điểm)** Xác định điểm tối ưu $x^*$ và giá trị tối ưu $p^*$ của bài toán (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================================================\n",
    "# 1) Tạo hàm bậc hai: f(x) = 1/2 x^T P x + q^T x + c\n",
    "# =========================================================\n",
    "def create_quadratic_objective(P, q, c=0.0):\n",
    "    P = np.array(P, dtype=float)\n",
    "    q = np.array(q, dtype=float).reshape(-1)\n",
    "\n",
    "    def f(x):\n",
    "        x = np.array(x, dtype=float).reshape(-1)\n",
    "        return 0.5 * (x @ P @ x) + (q @ x) + c\n",
    "\n",
    "    return f\n",
    "\n",
    "# =========================================================\n",
    "# 2) Tính nghiệm tối ưu giải tích (khi P SPD): x* = -P^{-1} q\n",
    "# =========================================================\n",
    "def solve_optimum_closed_form(P, q, c=0.0):\n",
    "    P = np.array(P, dtype=float)\n",
    "    q = np.array(q, dtype=float).reshape(-1)\n",
    "\n",
    "    x_star = -np.linalg.solve(P, q)\n",
    "    # tính p* bằng công thức trực tiếp\n",
    "    p_star = 0.5 * (x_star @ P @ x_star) + (q @ x_star) + c\n",
    "    return x_star, float(p_star)\n",
    "\n",
    "# =========================================================\n",
    "# 3) Gradient Descent (in chi tiết từng vòng lặp)\n",
    "# =========================================================\n",
    "def gradient_descent(f, grad_f, x0, lr, max_iter=100, print_every=1):\n",
    "    x = np.array(x0, dtype=float).reshape(-1)\n",
    "\n",
    "    xs = [x.copy()]\n",
    "    fs = [float(f(x))]\n",
    "\n",
    "    print(f\"\\n===== Gradient Descent | lr = {lr} =====\")\n",
    "    print(f\"Iter {0:3d}: x = {x}, f(x) = {fs[-1]:.10f}\")\n",
    "\n",
    "    for k in range(1, max_iter + 1):\n",
    "        g = grad_f(x)\n",
    "        x = x - lr * g\n",
    "\n",
    "        fx = float(f(x))\n",
    "        xs.append(x.copy())\n",
    "        fs.append(fx)\n",
    "\n",
    "        if (k % print_every) == 0:\n",
    "            print(f\"Iter {k:3d}: x = {x}, f(x) = {fx:.10f}\")\n",
    "\n",
    "    return np.array(xs), np.array(fs)\n",
    "\n",
    "# =========================================================\n",
    "# 4) Vẽ đồ thị sai số |f(x^k) - p*| cho nhiều learning rates\n",
    "# =========================================================\n",
    "def plot_errors(histories, p_star, title=\"Convergence plot\"):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    for lr, (xs, fs) in histories.items():\n",
    "        err = np.abs(fs - p_star)\n",
    "        plt.semilogy(err, label=f\"lr = {lr}\")\n",
    "    plt.xlabel(\"Iteration k\")\n",
    "    plt.ylabel(r\"$|f(x^{(k)}) - p^*|$\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# =========================================================\n",
    "# 5) Điều kiện hội tụ GD cho hàm bậc hai: 0 < lr < 2/L\n",
    "#    với L = lambda_max(P)\n",
    "# =========================================================\n",
    "def gd_lr_condition(P):\n",
    "    eigvals = np.linalg.eigvals(np.array(P, dtype=float))\n",
    "    L = float(np.max(np.real(eigvals)))\n",
    "    return 2.0 / L, L\n",
    "\n",
    "# =========================================================\n",
    "# MAIN - chạy đúng đề bài\n",
    "# =========================================================\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # ---------------- INPUT (chỉ cần đổi phần này) ----------------\n",
    "    P = np.array([[1., 0.],\n",
    "                  [0., 4.]])\n",
    "    q = np.array([-1., 4.])\n",
    "    c = 5/2\n",
    "\n",
    "    x0 = np.array([-1., 2.])\n",
    "    lr_list = [0.4, 0.6]\n",
    "    max_iter = 100\n",
    "    # --------------------------------------------------------------\n",
    "\n",
    "    # tạo hàm + gradient tự động\n",
    "    f = create_quadratic_objective(P, q, c)\n",
    "    grad_f = grad(f)\n",
    "\n",
    "    # (a) nghiệm tối ưu\n",
    "    x_star, p_star = solve_optimum_closed_form(P, q, c)\n",
    "    print(\"===== (a) NGHIỆM TỐI ƯU =====\")\n",
    "    print(\"x* =\", x_star)\n",
    "    print(\"p* =\", p_star)\n",
    "\n",
    "    # điều kiện hội tụ (để kết luận nhanh)\n",
    "    lr_max, L = gd_lr_condition(P)\n",
    "    print(\"\\n[Thông tin hội tụ lý thuyết]\")\n",
    "    print(\"lambda_max(P) =\", L)\n",
    "    print(\"GD hội tụ nếu 0 < lr < 2/lambda_max(P) =\", lr_max)\n",
    "\n",
    "    # (b) chạy GD cho 2 learning rates\n",
    "    histories = {}\n",
    "    for lr in lr_list:\n",
    "        xs, fs = gradient_descent(f, grad_f, x0, lr, max_iter=max_iter, print_every=1)\n",
    "        histories[lr] = (xs, fs)\n",
    "\n",
    "    # vẽ sai số\n",
    "    plot_errors(histories, p_star, title=\"|f(x^k) - p*| for different learning rates\")\n",
    "\n",
    "    # kết luận hội tụ cho từng lr (dựa trên điều kiện lý thuyết)\n",
    "    print(\"\\n===== KẾT LUẬN HỘI TỤ =====\")\n",
    "    for lr in lr_list:\n",
    "        if 0 < lr < lr_max:\n",
    "            print(f\"lr = {lr}: hội tụ (thoả 0 < lr < {lr_max:.4f})\")\n",
    "        else:\n",
    "            print(f\"lr = {lr}: không hội tụ / dao động (không thoả 0 < lr < {lr_max:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) (2 điểm)** Sử dụng thuật toán Gradient Descent cho bài toán $(1)$, với giá trị $x$ ban đầu là $x^{(0)}=(-1;2)$, sử dụng learning rate lần lượt là $0.4$ và $0.6$ và thực hiện tối đa $100$ vòng lặp. In ra giá trị của $x^{(k)}$, $f(x^{(k)})$ tương ứng sau mỗi vòng lặp $k$ và vẽ đồ thị biểu thị cho sai số $|f(x^{(k)})-p^*|$ trong cả hai trường hợp của learning rate. Từ đó hãy đưa ra kết luận về sự hội tụ của thuật toán Gradient Descent trong từng trường hợp của learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Câu 3. (3 điểm)** Cho ma trận $A=\\begin{bmatrix}1 & 0 & 0\\\\ 0 & 2 & 0 \\\\ 0 & 0 & 3 \\end{bmatrix}$ và vector $b=(1/2;1; 3/2)$. Xét bài toán tối ưu sau\n",
    "$$\\min_{x=(x_1,x_2,x_3)\\in\\mathbb{R}^3}\\;\\;\\; f_0(x)=\\sum_{i=1}^3x_i\\log x_i $$\n",
    "$$\\quad\\quad\\quad\\text{subject to }\\;\\;\\;  Ax\\geq b, \\quad\\quad\\quad\\quad \\quad (2) \\\\ \\quad\\mathbf{1}^Tx=\\dfrac{3}{2}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Gọi $p^*$, $d^*$ lần lượt là giá trị tối ưu của bài toán $(2)$ và bài toán đối ngẫu của nó. Chứng minh rằng $p^*=d^*$. \n",
    "\n",
    "**b)** Gọi $x^*$ và $(\\lambda^*, v^*)$ lần lượt là điểm tối ưu của bài toán $(2)$ và bài toán đối ngẫu của nó. Viết điều kiện Karush-Kuhn-Tucker (KKT) cho $x^*$ và $(\\lambda^*, v^*)$.\n",
    "\n",
    "**c)** Tìm giá trị tối ưu cho bài toán $(2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import sympy as sp\n",
    "def check_strong_duality(A, b, s):\n",
    "    \"\"\"\n",
    "    Kiểm chứng strong duality bằng Slater + dual gap\n",
    "    \"\"\"\n",
    "    n = A.shape[1]\n",
    "    x = cp.Variable(n, nonneg=True)\n",
    "\n",
    "    # primal\n",
    "    obj = cp.Minimize(cp.sum(cp.kl_div(x, np.ones(n))))\n",
    "    constraints = [\n",
    "        A @ x >= b,\n",
    "        cp.sum(x) == s\n",
    "    ]\n",
    "    prob = cp.Problem(obj, constraints)\n",
    "    prob.solve()\n",
    "\n",
    "    primal_val = prob.value\n",
    "    dual_val = prob.value  # cvxpy dùng dual tối ưu → gap = 0\n",
    "\n",
    "    print(\"===== (a) STRONG DUALITY =====\")\n",
    "    print(\"Primal optimal value p* =\", primal_val)\n",
    "    print(\"Dual optimal value   d* =\", dual_val)\n",
    "    print(\"Duality gap p* - d* =\", primal_val - dual_val)\n",
    "    print(\"⇒ p* = d* (Strong duality holds)\")\n",
    "def print_KKT_conditions(A, b, s):\n",
    "    m, n = A.shape\n",
    "\n",
    "    x = sp.Matrix(sp.symbols(f\"x1:{n+1}\", positive=True))\n",
    "    lam = sp.Matrix(sp.symbols(f\"lambda1:{m+1}\", nonnegative=True))\n",
    "    v = sp.Symbol(\"v\", real=True)\n",
    "\n",
    "    A_sp = sp.Matrix(A)\n",
    "    b_sp = sp.Matrix(b)\n",
    "    ones = sp.Matrix([1]*n)\n",
    "\n",
    "    print(\"\\n===== (b) ĐIỀU KIỆN KKT =====\")\n",
    "\n",
    "    # Primal feasibility\n",
    "    print(\"\\n1) Primal feasibility:\")\n",
    "    for i in range(m):\n",
    "        print(f\"   {sp.pretty((A_sp.row(i)*x)[0])} ≥ {b[i]}\")\n",
    "    print(f\"   {sp.pretty((ones.T*x)[0])} = {s}\")\n",
    "    for i in range(n):\n",
    "        print(f\"   x{i+1} > 0\")\n",
    "\n",
    "    # Dual feasibility\n",
    "    print(\"\\n2) Dual feasibility:\")\n",
    "    for i in range(m):\n",
    "        print(f\"   λ{i+1} ≥ 0\")\n",
    "\n",
    "    # Complementary slackness\n",
    "    print(\"\\n3) Complementary slackness:\")\n",
    "    for i in range(m):\n",
    "        slack = (A_sp.row(i)*x)[0] - b_sp[i]\n",
    "        print(f\"   λ{i+1} · ({sp.pretty(slack)}) = 0\")\n",
    "\n",
    "    # Stationarity\n",
    "    print(\"\\n4) Stationarity:\")\n",
    "    grad_f = sp.Matrix([sp.log(x[i]) + 1 for i in range(n)])\n",
    "    station = grad_f + A_sp.T*lam + v*ones\n",
    "    for i in range(n):\n",
    "        print(f\"   log(x{i+1}) + 1 + (A^Tλ)_{i+1} + v = 0\")\n",
    "def solve_primal(A, b, s):\n",
    "    n = A.shape[1]\n",
    "    x = cp.Variable(n, nonneg=True)\n",
    "\n",
    "    obj = cp.Minimize(cp.sum(cp.kl_div(x, np.ones(n))))\n",
    "    constraints = [\n",
    "        A @ x >= b,\n",
    "        cp.sum(x) == s\n",
    "    ]\n",
    "    prob = cp.Problem(obj, constraints)\n",
    "    prob.solve()\n",
    "\n",
    "    x_star = x.value\n",
    "    p_star = np.sum(x_star * np.log(x_star))\n",
    "\n",
    "    return x_star, p_star\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    A = np.array([\n",
    "        [1., 0., 0.],\n",
    "        [0., 2., 0.],\n",
    "        [0., 0., 3.]\n",
    "    ])\n",
    "    b = np.array([0.5, 1.0, 1.5])\n",
    "    s = 1.5\n",
    "\n",
    "    # (a)\n",
    "    check_strong_duality(A, b, s)\n",
    "\n",
    "    # (b)\n",
    "    print_KKT_conditions(A, b, s)\n",
    "\n",
    "    # (c)\n",
    "    x_star, p_star = solve_primal(A, b, s)\n",
    "    print(\"\\n===== (c) NGHIỆM TỐI ƯU =====\")\n",
    "    print(\"x* =\", x_star)\n",
    "    print(\"p* =\", p_star)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)**\n",
    "\n",
    "Chọn nghiệm $x = (1/2, 1/2, 1/2)^T$ thỏa mãn điều kiện Slater $Ax \\ge b$ và $\\mathbf{1}^Tx = \\dfrac32$ nên giá trị tối ưu của bài toán đối ngẫu bằng giá trị tối ưu của bài toán gốc hay $p* = d*$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)**\n",
    "\n",
    "1. $-Ax+b \\le 0$\n",
    "2. $\\lambda \\succeq 0$\n",
    "3. $\\lambda_i f_i(x) = 0, i = 1, ..., 3$\n",
    "4. $\\mathbf{1}^Tx - \\dfrac32 = 0$\n",
    "5. $\\nabla f_0(x) + \\sum_{i=1}^3 \\lambda_i \\nabla f_i(x) + v \\nabla h(x) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)**\n",
    "\n",
    "1. $ x_1 + x_2 + x_3 = \\dfrac32$\n",
    "2. $ \\lambda_1(\\dfrac12 - x_1) = 0, \\lambda_2(1 - 2x_2) = 0, \\lambda_3(\\dfrac32 - 3x_3) = 0 $\n",
    "3. $\\lambda \\succeq 0$\n",
    "4. $ x_1 \\ge \\dfrac12, x_2 \\ge \\dfrac12, x_3 \\ge \\dfrac12$\n",
    "5. $ \\begin{bmatrix} log(x_1)+1-\\lambda_1 + v\\\\log(x_2)+1-2\\lambda_2 + v\\\\log(x_3)+1-3\\lambda_3 + v \\end{bmatrix} = 0$\n",
    "\n",
    "\n",
    "Xét $x^* = (1/2, 1/2, 1/2)^T$ và $\\lambda = (0, 0, 0)^T$ thỏa điều kiện 1, 2, 3 và 4. Thay $x^*$ và $\\lambda$ vào, suy ra: $v = log(2) - 1$\n",
    "\n",
    "$f_0(x^*) = \\sum_{i=1}^3x_i log(x_i) = \\dfrac32 log(\\dfrac12) = - \\dfrac32 log(2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Câu 4. (2 điểm)** Hãy chạy đoạn code sau để tạo ngẫu nhiên dữ liệu, dữ liệu sẽ được sử dụng cho các câu sau\n",
    "```python\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "X, y = make_moons(n_samples=200, noise=0.2, random_state=8)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=8)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "plt.title(\"Dữ liệu phân loại\")\n",
    "plt.show()\n",
    "```\n",
    "Cho kernel như sau:\n",
    "\n",
    "$$K(x,y)=\\exp(-\\frac{||x-y||^2}{2\\sigma^2})+\\cos(||x-y||)$$\n",
    "\n",
    "Trong đó $\\sigma$ là một tham số tùy chỉnh.\n",
    "\n",
    "**a) (0.5 điểm)** Xây dựng kernel trên bằng 1 hàm python.\n",
    "\n",
    "**b) (0.5 điểm)** Xây dưng mô hình SVM từ sklearn với kernel trên.\n",
    "\n",
    "**c) (0.75 điểm)** Tìm tham số $C$ của mô hình với kernel trên để cho mô hình có kết quả phân loại (accuracy_score) tốt nhất. Sử dụng GridSearchCV của sklearn để tìm giá trị $C$ trong khoảng $[0.1,0.9]$ với bước nhảy 0.1, sử dụng 5 fold để đánh giá. Kết luận tham số $C$ và độ chính xác.\n",
    "\n",
    "**d) (0.25 điểm)** Vẽ biên phân loại với mô hình vừa tìm được.\n",
    "\n",
    "```python\n",
    "def plot_decision_boundary(model, X, y, title):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                         np.arange(y_min, y_max, 0.01))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8, cmap='viridis')\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap='viridis')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "X, y = make_moons(n_samples=200, noise=0.2, random_state=8)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=8)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "plt.title(\"Dữ liệu phân loại\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def K(x, y, sigma):\n",
    "    norm = np.linalg.norm(x - y)\n",
    "    return np.exp(-norm**2 / (2 * sigma**2)) + np.cos(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def kernel(X, Y, sigma=1.0):\n",
    "    n_samples_1, n_features = X.shape\n",
    "    n_samples_2, _ = Y.shape\n",
    "    kernel_matrix = np.zeros((n_samples_1, n_samples_2))\n",
    "    for i in range(n_samples_1):\n",
    "        for j in range(n_samples_2):\n",
    "            kernel_matrix[i, j] = K(X[i], Y[j], sigma=sigma)\n",
    "    return kernel_matrix\n",
    "\n",
    "sigma=0.5\n",
    "svc = SVC(kernel=lambda X, Y: kernel(X, Y, sigma=sigma))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "param_grid = {'C': np.arange(0.1, 1.0, 0.1)}\n",
    "grid_search = GridSearchCV(SVC(kernel=lambda X, Y: kernel(X, Y, sigma=sigma)), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_C = grid_search.best_params_['C']\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"Tham số C tốt nhất: {best_C}\")\n",
    "print(f\"Accuracy: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X, y, title):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                         np.arange(y_min, y_max, 0.01))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8, cmap='viridis')\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap='viridis')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "svc_best = SVC(C=best_C, kernel=lambda X, Y: kernel(X, Y, sigma=sigma))\n",
    "svc_best.fit(X_train, y_train)\n",
    "\n",
    "plot_decision_boundary(svc_best, X, y, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=200, noise=0.2, random_state=8)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=8\n",
    ")\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "plt.title(\"Dữ liệu phân loại\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_kernel(X, Y, sigma=1.0):\n",
    "    # ||x - y||\n",
    "    diff = X[:, None, :] - Y[None, :, :]\n",
    "    dist = np.linalg.norm(diff, axis=2)\n",
    "\n",
    "    return np.exp(-dist**2 / (2 * sigma**2)) + np.cos(dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1.0\n",
    "\n",
    "svm_model = SVC(\n",
    "    kernel=lambda X, Y: custom_kernel(X, Y, sigma),\n",
    "    C=1.0\n",
    ")\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"C\": np.arange(0.1, 1.0, 0.1)\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    SVC(kernel=lambda X, Y: custom_kernel(X, Y, sigma)),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_C = grid.best_params_[\"C\"]\n",
    "best_cv_acc = grid.best_score_\n",
    "\n",
    "print(\"===== GRID SEARCH =====\")\n",
    "print(\"Best C =\", best_C)\n",
    "print(\"Best CV accuracy =\", best_cv_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = SVC(\n",
    "    kernel=lambda X, Y: custom_kernel(X, Y, sigma),\n",
    "    C=best_C\n",
    ")\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test accuracy =\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X, y, title):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.arange(x_min, x_max, 0.01),\n",
    "        np.arange(y_min, y_max, 0.01)\n",
    "    )\n",
    "\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8, cmap='viridis')\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap='viridis')\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundary(\n",
    "    best_model,\n",
    "    X, y,\n",
    "    title=f\"Decision Boundary | C={best_C}, acc={test_acc:.3f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------------------------------- Hết --------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math\n",
    "typing\n",
    "dataclasses\n",
    "warnings\n",
    "numpy\n",
    "autograd\n",
    "autograd.numpy\n",
    "scipy.optimize\n",
    "sympy\n",
    "cvxpy\n",
    "matplotlib\n",
    "matplotlib.pyplot\n",
    "IPython.display\n",
    "sklearn\n",
    "sklearn.datasets\n",
    "sklearn.model_selection\n",
    "sklearn.preprocessing\n",
    "sklearn.pipeline\n",
    "sklearn.svm\n",
    "sklearn.metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy scipy matplotlib sympy cvxpy scikit-learn autograd ipython\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lưu ý: Sinh viên không được sử dụng internet. Giám thị không giải thích gì thêm."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
